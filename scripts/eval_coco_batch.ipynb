{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation FID, CLIP on COCO dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ The evaluation is based on the repositories: [Pytorch FID](https://github.com/mseitzer/pytorch-fid), and [CLIP Score](https://github.com/Taited/clip-score).\n",
    "+ The `.npz` file provided is cached from images generated by sd1.4, you can also produce this cache file by generating images with coco validation set and compute it using [Pytorch FID](https://github.com/mseitzer/pytorch-fid).\n",
    "+ Evaluating the clip score needs prompts from coco dataset, please unzip the `coco_prompts.zip` provided in huggingface to `data` path. After confirming that the directory below is correct, you can proceed with the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set eval dir here\n",
    "eval_dirs = [\n",
    "    \"/data1/cdd/code/github/trce-code/results/stage2_default_sexual/\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command_fid = \"python -m pytorch_fid {} ../data/cache/coco-sd14-gt.npz --device cuda:0\"\n",
    "command_clip =\" python -m clip_score {} ../data/coco_prompts --device cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir in eval_dirs:\n",
    "    dir = os.path.join(dir,\"coco-val\")\n",
    "    print(\"evaluating\", dir)\n",
    "    command1 = command_fid.format(dir)\n",
    "    command2 = command_clip.format(dir)\n",
    "    print(\"evaluating fid:\",dir)\n",
    "    fid = subprocess.run(command1,capture_output=True,shell=True)\n",
    "    print(\"evaluating clip score:\",dir)\n",
    "    clip = subprocess.run(command2,capture_output=True,shell=True)\n",
    "    print(\"fid:{}, clip:{}\".format(fid.stdout,clip.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
